Common Experience: Command Line Interface (technical spec notes)
================================================================

Since we want to minimize the code footprint of the CE system, we want to be able to build as much as possible
from as few building blocks as possible. Therefore the Command Line Interface is also structured around this
"building more from less" concept. We take shell pipes as our example and try to make them as lean as possible.

To achieve this, method chaining (*) similar to Unix shell pipes is used, but without the overhead
of the in/out conversion through the actual pipes or of running multiple instances of CE interpreter.
[ * https://en.wikipedia.org/wiki/Method_chaining ]

Each CE command is a "chain" of simple individual CE calls (A -> B -> C -> D).
Similar to Unix shell pipes, each individual CE call takes some input from the previous CE call
and passes some of its output to the next CE call. What gets passed between the calls is a "dynamic entry",
which serves as a source of code and parameters for the next CE call.

Naming all parameters, both obligatory and optional
---------------------------------------------------
In order to keep the CLI and the parser simple, for each individual CE call we employ "infix notation",
where each "verb" (method name) is preceded by "tweaks" (on-the-fly modifications to the "current object")
and followed by extra parameters for this call:

    ce --meta_optionX=... --meta_optionY=... --meta_optionZ=...
       .scalarP=... .listQ=+tail verb1 --param1a=... --param1b=... \
       .listR+=head              verb2 --param2a=... \
       .dictS.keyT=valueU        verb3 --param3a=... --param3b=...

Naturally, both "pre"-tweaks and "post"-parameters may be missing, depending on specific verbs or context.

This format is easy to parse, since all tweaks naturally start with a "." (standing for the root of the structure)
and provided all extra parameters are prefixed with "--" .

Ordering obligatory parameters, naming the optional ones
--------------------------------------------------------
Some verbs can have obligatory parameters, which allows us to skip the names of the obligatory parameters
provided the correct order of them is kept:

    ce --meta_optionX=... --meta_optionY=... --meta_optionZ=...
       .tweakP .tweakQ verb1 oblig1a --option1b=... --option1c=... \
                       verb2 --option2a=... \
       .tweakR         verb3 oblig3a oblig3b

This format is still easy to parse, provided we have a quick access to every method's signature.


Different ways of defining parameters - explanation
---------------------------------------------------
It depends on the verb which parameters it consumes. Assume "cmdX" consumes "alpha", "beta", "gamma" and "delta".
For "beta" and "delta" we have a default value in the dynamic entry.
Parameter "alpha" is obligatory, so we have to provide it anyway.
We also want to define new values for "gamma" and "delta", but we are happy with the default for "beta".
Because each parameter "alpha", "gamma" and "delta" can be defined on either side of the verb,
there are 8 ways to make it work:

    ce ... \
        cmdX --alpha=... --gamma=... --delta=...

    ce ... \
        .alpha=...  cmdX  --gamma=... --delta=...

    ...
    etc.

The difference here is what changes get passed along the chain.
For the parameters that you tweak on the left, the new values will make their way into the entry,
and may influence further calls along the chain,
while the parameters that you set on the right are for this particular call only, and will not get
automatically inherited.


Parameter precedence rule
-------------------------
What is the same parameter is defined in several places?
    paramX: valueA  # in the dynamic object
    .paramX=valueB  # in the tweaks on the left
    --paramX=valueC # in the call parameters on the right
The rule is valueC has highest precedence, followed by valueB, followed by valueA.


Simple two-step examples
------------------------
In the most typical 2-step linked pipeline scenario an entry has to be found/resolved first,
and then a method be called on the result(s).

    # Single-resolution example. Equivalent of 'ck locate env --tags=model,tflite,resnet' :
        ce find1 --query=env,model,tflite,resnet \
           tabulate --fields=location

Note 1. find1/findN() is a method central to the whole CE system. It searches for entries
        based on tags and attributes. The difference between the two versions is
        how many results they are expected to return (1 vs many).

Note 2. The object that is passed through the "virtual pipe" between the verbs is a CE entry,
        lazily loaded into an internal representation.

Note 3. tabulate() is a data projection method that formats outgoing data into simple tables
        that can be piped out of CE into traditional shell processing scripts.


Using the second format (ordering obligatory parameters instead of naming them) allows to write even less:

    # Single-resolution example. Equivalent of 'ck find env --tags=lib,armnn,rel.19.05,tflite,neon'
        ce find1 lib,armnn,rel.19.05,tflite,neon \
           tabulate entry_path

A resolution may return multiple entries. The following example iterates through them:

    # Multiple-resolution example. Equivalent of 'ck show env --tags=model,onnx,image-classification' :
        ce findN env,model,onnx,image-classification \
           tabulate data_uoa,name,version,tags --header! --format=...

An example with tweaks
----------------------
Since we pass an entry between verbs, we might as well make some on-the-fly changes, and even store the result:

    # On-the-spot editing example. Load an entry, make some in-memory changes to its meta data, then store under a different name.
    # The "post"-parameters are not properties of the object, but rather of the container collection
        ce find1 env,model,model_type=tflite \
           .param.x=15 .param.y=20 .meta.z=pqr  save  --new_name=... --new_collection=...

Note 1. Tweaking allows to edit different types of data according to their nature
        ( override scalars, push/unshift/seek-and-remove arrays, add or remove dictionary entries, etc).

Note 2. save() by default stores changes in the original entry, but if --new_name or --new_collection is given, can make an (edited) copy.


Other ways to start the flow
----------------------------
Finding an entry using its name (way faster than using tags/attribs query, but less portable):

        ce from python-package-tensorflow-1.12 \
           install

        ce from python-package-tensorflow-1.12 \
           .version=1.13 .tags-=v1.12 .tags=+v1.13  save  --name=python-package-tensorflow-1.13


Starting from scratch (assuming an empty entry by default)
----------------------------------------------------------
        ce save --name=new_empty_ce_entry_in_dynamic_collection

This "default" empty entry can, of course, be modified on the fly
-----------------------------------------------------------------
        ce .alpha=15 .extlist=[png,git,jpg]  save  --name=new_ce_entry_in_dynamic_collection


Meta data can also be fed from an external file
-----------------------------------------------
            ce json_input --input_file=xyz.json  save  --name=...

or from standard input (assuming JSON input) :

            jq ... | ce json_input save --name=...


Multi-environment resolve examples
----------------------------------
    # resolve() runs "find1" on each entry in deps{} , adding "env" type on the fly, and outputs env{} , merged in the correct order
        ce from env \
           .deps.lib.query=lib,tflite .deps.model.query=model,tflite .deps.images.query=preprocessed,imagenet  resolve \
           json_output

    # M-to-1 resolution. Equivalent of 'ck virtual env --tag_groups="lib,tflite model,tflite preprocessed,imagenet' :
        ce from env \
           .deps=+{query=lib,tflite} .deps=+{query=model,tflite} .deps=+{query=preprocessed,imagenet}  resolve \
           shell --cmd=...


    # Assumes automatic resolve()
        ce find1 program,image-classification,tf,cpp \
            run

    # Test resolve() for a particular program (assumes "program" inherits from "env" - or at least from "resolvable" interface):
        ce find1 program,image-classification,tf,cpp \
            resolve

Note: resolve() is a method of env , so we either have to "from" this entry, or "find1" a descendant of it.


CLI user-facing commands:
=========================

There is an opportunity to tune the whole CE call by sticking "meta level" options before the first verb:
    ce --core_collection=... --dynamic_collection=...  from  package-X install
    ce --version

(collection access)
    bypath <entry_path>                                     1->1    # lazily loads an entry by path
    byname <entry_name> [collection=dynamic]                1->1    # looks up (and lazily loads) an entry by name
    find1 <query> [collection=dynamic]                      1->1    # finds (and lazily loads) an entry by query
    from <entry_path/entry_name/query> [collection=dynamic] 1->1    # syntactic sugar to try bypath(), then byname(), then find1()
    findN <query> [collection=dynamic]                      1->N    # finds multiple entries using query
    save [name] [mid_path] [collection=dynamic]             1->1    # update or store a new entry
    detach                                                  1->1    # removes an entry from its collection, but passes it on so it can be stored elsewhere

(input/output)
    json_input [input_file]                                 1->1    # load an entry from STDIN or JSON file
    json_output [output_file]                               N->1    # output JSON to STDOUT or a file
    tabulate <fields> [separator] [format]                  N->1    # output in tabular format

(env/resolvable)
    resolve [deps] [collection=dynamic]                     1->1    # uniquely resolve given deps (defined either in an entry or from cli)
    shell [cmd]                                             1->1    # run shell interactively or a given command in it. Consume environment generated by resolve()

(git repo)
    pull <url> <name>                                       1->1    # create a new local collection by cloning a git repo, or pull if it already exists

(env/downloadable/soft/package)
    download <url> [tags] [attribs]                         1->1    # download an external file (defined by URL) and store it as a local entry
    fs_find [patterns_to_match] [search_path]               1->N    # the internal mechanism behind finding matching files for software detection
    detect [full_path] [search_path]                        1->1    # find a given pre-installed package and set up an environment entry pointing at it
    install [package_version] [package_options]             1->1    # install/build a package in a new entry

(program)
    compile                                                 1->1    # builds the code and creates a temporary entry (in /tmp ?), passing it on for execution
                                                                    # This "compiled" entry adds code, but inherits the rest from the "source" entry (so is not designed to work without it)
    run [repetitions=1]                                     1->1    # runs and creates a "running report" structure, suitable for recording as an experiment


Current directory as an entry
-----------------------------
To avoid unpredictable behaviour, but still support the concept of "current dir as an entry",
this functionality has to be explicitly required:
    ce from . install
    ce from . detect
Note that entries loaded this way do not know to which collection they belong.
So collection-related operations with the "cwd entry" are discouraged.

The pattern above can also be extended to any path, not necessarily just ".",
and not even necessarily absolute.


Moving entries around
---------------------
    ce find1 model,tflite,resnet \
        detach \                                                    # removes entry from dynamic collection, but does not delete it
        save --collection=ce_inference --rel_path=models/tflite     # assume --name is kept even when original collection has been forgotten

Bulk-editing of entries (and storing as modified copies):
    ce findN model,model_type=tflite,channel_order=nhwc \
        .propertyX=.propertyZ .tags=+",modified"  save  --name=+"_modified"


Recording a particular program run:
    ce from program-image-classification-tf-py \
        .deps.model.query=+",resnet" .runtime_env.CK_BATCH_COUNT=20  run  --repetitions=10 \
        .model_type=tf .batches=20 .tags=+resnet  save  --name=experiment-tf-batch.20

Compile and run:
    ce from program-image-classification-tflite-cpp \
        .build_deps.cmake.version=3.14 .build_deps.cpp.query=+clang  compile  \
        save --name=compiled-program-image-classification-tflite-clang \
        .deps.model.query=+",resnet" .runtime_env.CK_BATCH_COUNT=10  run  --repetitions=1 \
        .model_type=tflite .batches=10 .tags=+resnet  save  --name=experiment-tflite-clang-resnet-batches.10-reps.1

Running it again:
    ce from compiled-program-image-classification-tflite-clang \
        .deps.model.query=+",mobilenet" .runtime_env.CK_BATCH_COUNT=10  run  --repetitions=5 \
        .model_type=tflite .batches=100 .tags=+mobilenet  save  --name=experiment-tflite-clang-mobilenet-batches.100-reps.5

Cross-compile and run:
    ce from program-image-classification-tflite-cpp \
        .build_deps.cmake.version=3.14 .build_deps.cpp.query=+clang  compile  --target_os=android24-arm8a \
        save --name=compiled-program-image-classification-tflite-clang-for-android24 \
        .deps.model.query=+",mobilenet" .runtime_env.CK_BATCH_COUNT=15  run  --device=my_phone \
        .model_type=tflite .batches=15 .tags=+mobilenet  save  --name=experiment-tflite-clang-mobilenet-batches.15-on.my_phone


Unresolved questions:
===================================================================
*) working with 1->N and N->1 methods, passing results around
*) Introduce a generic manual selection method to enforce N->1 transformation?
*) Searching for entries by "class":  ISA(env)
*) Searching for entries by matching name against a wildcard (or any scalar field against a wildcard? or any scalar field against a generic pattern?)
*) Can we bootstrap without dynamic_collection ?
*) Storing final/intermediate results we have not been asked to store? (but potentially took long to produce)
*) Intermediate data format into which the CLI parser can parse (esp. editing), and which can be independently generated and consumed by "task runner"
*) Should "proper parameters" (that will parameterize future calls) be stored separately from entry's "meta parameters" (such as parent_name[s])?
    What is the danger in keeping everything in one big pile?
*) A good CLI API to the "ephemeral" parameters of entries that are not stored (path, name, ...) but may still have to be referred to?

*) What should a simple user method ( fibonacci() or factorial() ) return, and how to wrap it universally?
    We can work with "non-conforming" functions and just call them using our reparam infrastructure.
    But what would be the best wrapping strategy?
        If it returns a dictionary - leave it alone, pretend that this dictionary is the "output entry" which can be recorded or worked with otherwise.
        If it returns something else - wrap it into a dictionary:
            { 'return_value': 120, 'method_called': 'factorial', 'effective_call_parameters': {'n': 5} }
        Can we somehow signal from CLI to wrap output even if a dictionary is expected in return?
